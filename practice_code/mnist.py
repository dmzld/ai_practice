# -*- coding: utf-8 -*-
"""MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XNnlcPlzTK54Rdu3EMyuUxFux83wEUYp
"""

import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data


def xavier_init(n_inputs, n_outputs, uniform = True):
  if uniform :
    init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))
    return tf.random_uniform_initializer(-init_range, init_range)
  else :
    stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))
    return tf.truncated_normal_initializer(stddev=stddev)

dropout_rate = tf.placeholder("float")


mnist = input_data.read_data_sets("MNIST_data/",one_hot=True, validation_size=50000)
print("Training dataset :", len(mnist.train.labels),
     "\nTesting dataset :", len(mnist.test.labels),
     "\nValidation dataset :", len(mnist.validation.labels))

learning_rate = 0.3
epochs = 300
batch_size = 100

n_input = 784

n_hidden1 = 300

n_output = 10

x = tf.placeholder("float", [None, n_input])
y = tf.placeholder("float", [None, n_output])

W1 = tf.Variable(tf.truncated_normal([n_input, n_hidden1], stddev=0.1, name = 'W1'))
b1 = tf.Variable(tf.zeros([n_hidden1], name = 'b1'))

W6 = tf.Variable(tf.truncated_normal([n_hidden1, n_output], stddev=0.1, name = 'W6'))
b6 = tf.Variable(tf.zeros([n_output], name = 'b6'))

hidden_out1 = tf.nn.relu(tf.add(tf.matmul(x, W1), b1))
y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_out1, W6), b6))

y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)

error = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped)
                                     + (1 - y) * tf.log(1 - y_clipped), axis = 1))

#optimiser = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(error)
optimiser = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(error)


init_op = tf.global_variables_initializer()

correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
float_vector = tf.cast(correct_prediction, "float")
accuracy = tf.reduce_mean(float_vector)

with tf.Session() as sess:
  sess.run(init_op)
  iteration = int(len(mnist.train.labels) / batch_size)
  for epoch in range(epochs):
    avg_error = 0
    for i in range(iteration):
      batch_x, batch_y = mnist.train.next_batch(batch_size = batch_size)
      
      _, er = sess.run([optimiser, error], feed_dict = {x: batch_x, y: batch_y})
      avg_error += er / iteration
      
    if((epoch+1)%5 == 0):
      print("Epoch: ", (epoch + 1), "error =", "{:.3f}".format(avg_error))
      
  print("Accuracy: ", sess.run(accuracy, feed_dict = {x: mnist.test.images, y: mnist.test.labels}))